{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7baf5490-4ab3-449d-afcd-672fe3cd14f6",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>GRADE</th><th>ROll_NO</th><th>DATE</th><th>MARKS</th></tr></thead><tbody><tr><td>A</td><td>1</td><td>2003-05-23</td><td>100</td></tr><tr><td>B</td><td>2</td><td>2003-05-23</td><td>200</td></tr><tr><td>A</td><td>4</td><td>2003-05-23</td><td>200</td></tr><tr><td>B</td><td>3</td><td>2003-05-22</td><td>200</td></tr><tr><td>A</td><td>5</td><td>2003-05-21</td><td>500</td></tr><tr><td>A</td><td>1</td><td>2003-05-20</td><td>600</td></tr><tr><td>C</td><td>2</td><td>2003-05-23</td><td>400</td></tr><tr><td>A</td><td>4</td><td>2003-05-23</td><td>200</td></tr><tr><td>C</td><td>6</td><td>2003-05-22</td><td>400</td></tr><tr><td>A</td><td>5</td><td>2003-05-21</td><td>500</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A",
         1,
         "2003-05-23",
         100
        ],
        [
         "B",
         2,
         "2003-05-23",
         200
        ],
        [
         "A",
         4,
         "2003-05-23",
         200
        ],
        [
         "B",
         3,
         "2003-05-22",
         200
        ],
        [
         "A",
         5,
         "2003-05-21",
         500
        ],
        [
         "A",
         1,
         "2003-05-20",
         600
        ],
        [
         "C",
         2,
         "2003-05-23",
         400
        ],
        [
         "A",
         4,
         "2003-05-23",
         200
        ],
        [
         "C",
         6,
         "2003-05-22",
         400
        ],
        [
         "A",
         5,
         "2003-05-21",
         500
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "GRADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ROll_NO",
         "type": "\"long\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"date\""
        },
        {
         "metadata": "{}",
         "name": "MARKS",
         "type": "\"long\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import DataFrame\n",
    "from pyspark.sql.functions import *\n",
    "\n",
    "spark= SparkSession.builder.appName('task_1').getOrCreate()\n",
    "\n",
    "data=[\n",
    "    ('A',1,'5/23/2003',100),\n",
    "    ('B',2,'5/23/2003',200),\n",
    "    ('A',4,'5/23/2003',200),\n",
    "    ('B',3,'5/22/2003',200),\n",
    "    ('A',5,'5/21/2003',500),\n",
    "    ('A',1,'5/20/2003',600),\n",
    "    ('C',2,'5/23/2003',400),\n",
    "    ('A',4,'5/23/2003',200),\n",
    "    ('C',6,'5/22/2003',400),\n",
    "    ('A',5,'5/21/2003',500),\n",
    "]\n",
    "df= spark.createDataFrame(data,['GRADE','ROll_NO','DATE','MARKS'])\n",
    "df = df.withColumn(\"DATE\", to_date(\"DATE\", \"M/d/yyyy\"))\n",
    "# sorted_df2 = df.orderBy(\"Date\")\n",
    "\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "b0993dc8-9b3e-4a42-8226-9bfe21dc2d04",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>GRADE</th><th>ROll_NO</th><th>DATE</th><th>MARKS</th></tr></thead><tbody><tr><td>A - 60.0%</td><td>1 - 20.0%</td><td>2003-05-23 - 50.0%</td><td>200 - 40.0%</td></tr><tr><td>B - 20.0%</td><td>2 - 20.0%</td><td>2003-05-21 - 20.0%</td><td>400 - 20.0%</td></tr><tr><td>C - 20.0%</td><td>4 - 20.0%</td><td>2003-05-22 - 20.0%</td><td>500 - 20.0%</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>2003-05-20 - 10.0%</td><td>100 - 10.0%</td></tr><tr><td>null</td><td>3 - 10.0%</td><td>null</td><td>600 - 10.0%</td></tr><tr><td>null</td><td>6 - 10.0%</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A - 60.0%",
         "1 - 20.0%",
         "2003-05-23 - 50.0%",
         "200 - 40.0%"
        ],
        [
         "B - 20.0%",
         "2 - 20.0%",
         "2003-05-21 - 20.0%",
         "400 - 20.0%"
        ],
        [
         "C - 20.0%",
         "4 - 20.0%",
         "2003-05-22 - 20.0%",
         "500 - 20.0%"
        ],
        [
         null,
         "5 - 20.0%",
         "2003-05-20 - 10.0%",
         "100 - 10.0%"
        ],
        [
         null,
         "3 - 10.0%",
         null,
         "600 - 10.0%"
        ],
        [
         null,
         "6 - 10.0%",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "GRADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ROll_NO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MARKS",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "def transform_dataframe(input_df):\n",
    "\n",
    "    dfs = []\n",
    "    for i in input_df.columns:\n",
    " \n",
    "        id_count = input_df.groupBy(i).agg(count('*').alias('count'))\n",
    "        id_count_sorted = id_count.orderBy(['count', i], ascending=[False, True])\n",
    "        percentage = format_number((id_count_sorted['count'] / input_df.count()) * 100, 1)\n",
    "       \n",
    "        percentage_with_percent = concat(i,lit(' - '),percentage, lit('%'))\n",
    "      \n",
    "        value_count_df = id_count_sorted.withColumn(i, percentage_with_percent)\n",
    "       \n",
    "        value_count_df = value_count_df.select(i)\n",
    "        \n",
    "        value_count_df = value_count_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "     \n",
    "        dfs.append(value_count_df)\n",
    "      \n",
    "        x = dfs[0]\n",
    "        for i in dfs[1:]:\n",
    "            x = x.join(i, \"ID\", \"full\")\n",
    "\n",
    "\n",
    "    return x.drop(\"ID\")\n",
    "\n",
    "transformed_df = transform_dataframe(df)\n",
    "\n",
    "display(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "481da965-66b6-4880-87de-6b214dcd7c48",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>GRADE</th><th>ROll_NO</th><th>DATE</th><th>MARKS</th></tr></thead><tbody><tr><td>A - 60.0%</td><td>1 - 20.0%</td><td>2003-05-23 - 50.0%</td><td>200 - 40.0%</td></tr><tr><td>null</td><td>2 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>4 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A - 60.0%",
         "1 - 20.0%",
         "2003-05-23 - 50.0%",
         "200 - 40.0%"
        ],
        [
         null,
         "2 - 20.0%",
         null,
         null
        ],
        [
         null,
         "4 - 20.0%",
         null,
         null
        ],
        [
         null,
         "5 - 20.0%",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "GRADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ROll_NO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MARKS",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "def transform_dataframe(input_df):\n",
    "    dfs = []\n",
    "    for i in input_df.columns:\n",
    "        id_count = input_df.groupBy(i).agg(count('*').alias('count'))\n",
    "        total_count = input_df.count()\n",
    "        id_count_with_percentage = id_count.withColumn(\"percentage\", (id_count['count'] / total_count) * 100)\n",
    "        max_percentage = id_count_with_percentage.agg(spark_max(\"percentage\")).collect()[0][0]\n",
    "        max_percentage_rows = id_count_with_percentage.filter(id_count_with_percentage[\"percentage\"] == max_percentage)\n",
    "        value_count_df = max_percentage_rows.withColumn(i, concat(i, lit(' - '), col(\"percentage\").cast(\"string\"), lit('%')))\n",
    "        value_count_df = value_count_df.select(i)\n",
    "        value_count_df = value_count_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "        dfs.append(value_count_df)\n",
    "      \n",
    "    x = dfs[0]\n",
    "    for i in dfs[1:]:\n",
    "        x = x.join(i, \"ID\", \"full\")\n",
    "\n",
    "    return x.drop(\"ID\")\n",
    "\n",
    "transformed_df = transform_dataframe(df)\n",
    "display(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "3e347196-7ede-44dc-bf81-4581214d6c62",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>GRADE</th><th>ROll_NO</th><th>DATE</th><th>MARKS</th></tr></thead><tbody><tr><td>A - 60.0%</td><td>1 - 20.0%</td><td>2003-05-23 - 50.0%</td><td>200 - 40.0%</td></tr><tr><td>null</td><td>2 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>4 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>B - 20.0%</td><td>1 - 20.0%</td><td>2003-05-21 - 20.0%</td><td>500 - 20.0%</td></tr><tr><td>C - 20.0%</td><td>2 - 20.0%</td><td>2003-05-22 - 20.0%</td><td>400 - 20.0%</td></tr><tr><td>null</td><td>4 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A - 60.0%",
         "1 - 20.0%",
         "2003-05-23 - 50.0%",
         "200 - 40.0%"
        ],
        [
         null,
         "2 - 20.0%",
         null,
         null
        ],
        [
         null,
         "4 - 20.0%",
         null,
         null
        ],
        [
         null,
         "5 - 20.0%",
         null,
         null
        ],
        [
         "B - 20.0%",
         "1 - 20.0%",
         "2003-05-21 - 20.0%",
         "500 - 20.0%"
        ],
        [
         "C - 20.0%",
         "2 - 20.0%",
         "2003-05-22 - 20.0%",
         "400 - 20.0%"
        ],
        [
         null,
         "4 - 20.0%",
         null,
         null
        ],
        [
         null,
         "5 - 20.0%",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "GRADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ROll_NO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MARKS",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit\n",
    "\n",
    "def transform_dataframe(input_df):\n",
    "    dfs = []\n",
    "    for i in input_df.columns:\n",
    "        id_count = input_df.groupBy(i).agg(count('*').alias('count'))\n",
    "        total_count = input_df.count()\n",
    "        id_count_with_percentage = id_count.withColumn(\"percentage\", (id_count['count'] / total_count) * 100)\n",
    "        sorted_id_count = id_count_with_percentage.orderBy(col(\"percentage\").desc())\n",
    "        max_percentage = sorted_id_count.select(\"percentage\").first()[0]\n",
    "        second_max_percentage = sorted_id_count.select(\"percentage\").limit(2).collect()[-1][0]\n",
    "        rows_with_max_percentage = id_count_with_percentage.filter(col(\"percentage\") == max_percentage)\n",
    "        rows_with_second_max_percentage = id_count_with_percentage.filter(col(\"percentage\") == second_max_percentage)\n",
    "        combined_rows = rows_with_max_percentage.union(rows_with_second_max_percentage)\n",
    "        value_count_df = combined_rows.withColumn(i, concat(i, lit(' - '), col(\"percentage\").cast(\"string\"), lit('%')))\n",
    "        value_count_df = value_count_df.select(i)\n",
    "        value_count_df = value_count_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "        dfs.append(value_count_df)\n",
    "      \n",
    "    x = dfs[0]\n",
    "    for i in dfs[1:]:\n",
    "        x = x.join(i, \"ID\", \"full\")\n",
    "\n",
    "    return x.drop(\"ID\")\n",
    "\n",
    "transformed_df = transform_dataframe(df)\n",
    "display(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "8bc8a9f4-0dab-4e3e-a8d7-e30f3612403d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>GRADE</th><th>ROll_NO</th><th>DATE</th><th>MARKS</th></tr></thead><tbody><tr><td>A - 60.0%</td><td>1 - 20.0%</td><td>2003-05-23 - 50.0%</td><td>200 - 40.0%</td></tr><tr><td>null</td><td>2 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>4 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>A - 60.0%</td><td>1 - 20.0%</td><td>2003-05-23 - 50.0%</td><td>200 - 40.0%</td></tr><tr><td>null</td><td>2 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>4 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A - 60.0%",
         "1 - 20.0%",
         "2003-05-23 - 50.0%",
         "200 - 40.0%"
        ],
        [
         null,
         "2 - 20.0%",
         null,
         null
        ],
        [
         null,
         "4 - 20.0%",
         null,
         null
        ],
        [
         null,
         "5 - 20.0%",
         null,
         null
        ],
        [
         "A - 60.0%",
         "1 - 20.0%",
         "2003-05-23 - 50.0%",
         "200 - 40.0%"
        ],
        [
         null,
         "2 - 20.0%",
         null,
         null
        ],
        [
         null,
         "4 - 20.0%",
         null,
         null
        ],
        [
         null,
         "5 - 20.0%",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "GRADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ROll_NO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MARKS",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit, monotonically_increasing_id\n",
    "\n",
    "def transform_dataframe(input_df):\n",
    "    dfs = []\n",
    "    for i in input_df.columns:\n",
    "        id_count = input_df.groupBy(i).count()\n",
    "        total_count = input_df.count()\n",
    "        id_count_with_percentage = id_count.withColumn(\"percentage\", (id_count['count'] / total_count) * 100)\n",
    "        sorted_id_count = id_count_with_percentage.orderBy(col(\"percentage\").desc())\n",
    "        max_percentage = sorted_id_count.select(\"percentage\").first()[0]\n",
    "        second_max_percentage = sorted_id_count.select(\"percentage\").limit(1).collect()[-1][0]\n",
    "        rows_with_max_percentage = id_count_with_percentage.filter(col(\"percentage\") == max_percentage)\n",
    "        rows_with_second_max_percentage = id_count_with_percentage.filter(col(\"percentage\") == second_max_percentage)\n",
    "        combined_rows = rows_with_max_percentage.union(rows_with_second_max_percentage)\n",
    "        # Concatenate the percentage to each column value\n",
    "        value_count_df = combined_rows.withColumn(i, concat(i, lit(' - '), col(\"percentage\").cast(\"string\"), lit('%')))\n",
    "        # Select only the transformed column\n",
    "        value_count_df = value_count_df.select(i)\n",
    "        # Add a unique identifier column for joining\n",
    "        value_count_df = value_count_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "        dfs.append(value_count_df)\n",
    "      \n",
    "    # Join the DataFrames column-wise\n",
    "    x = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        x = x.join(dfs[i], \"ID\", \"full\")\n",
    "\n",
    "    # Sort the DataFrame to place null values at the end\n",
    "    sorted_columns = [col for col in x.columns if col != \"ID\"]\n",
    "    x = x.select(sorted_columns)\n",
    "    \n",
    "    return x\n",
    "\n",
    "transformed_df = transform_dataframe(df)\n",
    "display(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "87069393-6be1-4a83-8e99-5e55e8c66d7f",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/html": [
       "<style scoped>\n",
       "  .table-result-container {\n",
       "    max-height: 300px;\n",
       "    overflow: auto;\n",
       "  }\n",
       "  table, th, td {\n",
       "    border: 1px solid black;\n",
       "    border-collapse: collapse;\n",
       "  }\n",
       "  th, td {\n",
       "    padding: 5px;\n",
       "  }\n",
       "  th {\n",
       "    text-align: left;\n",
       "  }\n",
       "</style><div class='table-result-container'><table class='table-result'><thead style='background-color: white'><tr><th>GRADE</th><th>ROll_NO</th><th>DATE</th><th>MARKS</th></tr></thead><tbody><tr><td>A - 60.0%</td><td>1 - 20.0%</td><td>2003-05-23 - 50.0%</td><td>200 - 40.0%</td></tr><tr><td>null</td><td>2 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>4 - 20.0%</td><td>null</td><td>null</td></tr><tr><td>null</td><td>5 - 20.0%</td><td>null</td><td>null</td></tr></tbody></table></div>"
      ]
     },
     "metadata": {
      "application/vnd.databricks.v1+output": {
       "addedWidgets": {},
       "aggData": [],
       "aggError": "",
       "aggOverflow": false,
       "aggSchema": [],
       "aggSeriesLimitReached": false,
       "aggType": "",
       "arguments": {},
       "columnCustomDisplayInfos": {},
       "data": [
        [
         "A - 60.0%",
         "1 - 20.0%",
         "2003-05-23 - 50.0%",
         "200 - 40.0%"
        ],
        [
         null,
         "2 - 20.0%",
         null,
         null
        ],
        [
         null,
         "4 - 20.0%",
         null,
         null
        ],
        [
         null,
         "5 - 20.0%",
         null,
         null
        ]
       ],
       "datasetInfos": [],
       "dbfsResultPath": null,
       "isJsonSchema": true,
       "metadata": {},
       "overflow": false,
       "plotOptions": {
        "customPlotOptions": {},
        "displayType": "table",
        "pivotAggregation": null,
        "pivotColumns": null,
        "xColumns": null,
        "yColumns": null
       },
       "removedWidgets": [],
       "schema": [
        {
         "metadata": "{}",
         "name": "GRADE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "ROll_NO",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "DATE",
         "type": "\"string\""
        },
        {
         "metadata": "{}",
         "name": "MARKS",
         "type": "\"string\""
        }
       ],
       "type": "table"
      }
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from pyspark.sql.functions import col, concat, lit, monotonically_increasing_id\n",
    "\n",
    "def transform_dataframe(input_df, N):\n",
    "    dfs = []\n",
    "    for i in input_df.columns:\n",
    "        id_count = input_df.groupBy(i).count()\n",
    "        total_count = input_df.count()\n",
    "        id_count_with_percentage = id_count.withColumn(\"percentage\", (id_count['count'] / total_count) * 100)\n",
    "        sorted_id_count = id_count_with_percentage.orderBy(col(\"percentage\").desc())\n",
    "        max_percentage = sorted_id_count.select(\"percentage\").limit(N).collect()[-1][0]\n",
    "        rows_with_max_percentage = id_count_with_percentage.filter(col(\"percentage\") == max_percentage)\n",
    "        value_count_df = rows_with_max_percentage.withColumn(i, concat(i, lit(' - '), col(\"percentage\").cast(\"string\"), lit('%')))\n",
    "        value_count_df = value_count_df.select(i)\n",
    "        value_count_df = value_count_df.withColumn(\"ID\", monotonically_increasing_id())\n",
    "        dfs.append(value_count_df)\n",
    "      \n",
    "    x = dfs[0]\n",
    "    for i in range(1, len(dfs)):\n",
    "        x = x.join(dfs[i], \"ID\", \"full\")\n",
    "\n",
    "    return x.drop(\"ID\")\n",
    "\n",
    "# Example usage: Specify the Nth highest percentage you want (e.g., N=1 for the highest percentage)\n",
    "transformed_df = transform_dataframe(df, N=1)\n",
    "display(transformed_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "421fcb48-53ef-4664-a413-25783e9b2529",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "feb 12 2",
   "widgets": {}
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
